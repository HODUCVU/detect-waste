{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision.transforms as T\n",
    "from matplotlib import pyplot as plt\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/dih4/dih4_2/wimlds/smajchrowska/maskrcnn_RN50/checkpoint_20.pth'\n",
    "IMG_NAME = '/dih4/dih4_2/wimlds/data/all_detect_images/dumped/99toMesVaOHKd8lOIZBVKS1MDPlXSPkTmdijxfiO.jpeg' # wszystko\n",
    "NUM_CLASSES = 2\n",
    "THRESHOLD = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ['Litter']\n",
    "\n",
    "# standard PyTorch mean-std input image normalization\n",
    "transform = T.Compose([\n",
    "    T.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import get_instance_segmentation_model\n",
    "\n",
    "model = get_instance_segmentation_model(NUM_CLASSES)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# read an image\n",
    "im = Image.open(IMG_NAME).convert('RGB')\n",
    "\n",
    "# mean-std normalize the input image (batch-size: 1)\n",
    "img = transform(im).unsqueeze(0)\n",
    "\n",
    "outputs = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "img = np.array(im)[:,:,1]\n",
    "plt.imshow(im)\n",
    "ax = plt.gca()\n",
    "keep = outputs[0]['scores'].detach().numpy() > THRESHOLD\n",
    "prob = outputs[0]['scores'].detach().numpy()[keep].tolist()\n",
    "labels = outputs[0]['labels'].detach().numpy()[keep].tolist()\n",
    "masks = outputs[0]['masks'].detach().numpy()[keep]\n",
    "\n",
    "masking = np.zeros((1,)+img.shape)\n",
    "for j, i in enumerate(outputs[0]['boxes'].detach().numpy()[keep].tolist()):\n",
    "    p = prob[j]\n",
    "    masking += masks[j]\n",
    "    ax.add_patch(plt.Rectangle((i[0], i[1]), i[2] - i[0], i[3] - i[1],\n",
    "                                   fill=False, color='r', linewidth=3))\n",
    "    cl = int(labels[j])-1\n",
    "    text = f'{CLASSES[cl]}: {p:0.2f}'\n",
    "    ax.text(i[0], i[1], text, fontsize=15,\n",
    "            bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "\n",
    "imagines = np.array(im)\n",
    "imagines[:,:,0] = imagines[:,:,0] + masking[0,:,:]*100\n",
    "plt.imshow(imagines)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.imshow(masking[0,:,:])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "efficientdet",
   "language": "python",
   "name": "efficientdet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
